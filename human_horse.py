# -*- coding: utf-8 -*-
"""Human horse

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gL8S5Dj_fEGyBWVv69nnhYuuLoCqDoey
"""

import keras
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
import os
import cv2
import numpy as np
from time import time
from tensorflow.keras import utils
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
# %matplotlib inline

from google.colab import drive
drive.mount('/content/gdrive')

!unzip gdrive/My\ Drive/archive (3).zip

train_data = '/content/gdrive/My Drive/asl_alphabet_test/horse-or-human/train'
test_data='/content/gdrive/My Drive/asl_alphabet_test/horse-or-human/horse-or-human/validation/validation'

train_data_gen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

train_data1 = train_data_gen.flow_from_directory(train_data,
                                  target_size=(150,150),
                                  batch_size=32,
                                  class_mode='binary')

train_data1.class_indices

validation_data_gen = ImageDataGenerator(rescale=1./255)

validation_data1 = validation_data_gen.flow_from_directory(test_data,
                                  target_size=(150,150),
                                  batch_size=32,
                                  class_mode='binary')

def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20, 20))
    axes = axes.flatten()
    for img, ax in zip(images_arr, axes):
        ax.imshow(img)
    plt.tight_layout()
    plt.show()

images = [train_data1[0][0][0] for i in range(5)]
plotImages(images)

cnn_model = keras.models.Sequential([
    keras.layers.Conv2D(filters=32, kernel_size=3, input_shape=[150,150,3]),
    keras.layers.MaxPooling2D(pool_size=(2,3)),
    keras.layers.Conv2D(filters=64, kernel_size=3),
    keras.layers.MaxPooling2D(pool_size=(2,2)),
    keras.layers.Conv2D(filters=128, kernel_size=3),
    keras.layers.MaxPooling2D(pool_size=(2,2)),
    keras.layers.Conv2D(filters=256, kernel_size=3),
    keras.layers.MaxPooling2D(pool_size=(2,2)),
    
    keras.layers.Dropout(0.5),
    keras.layers.Flatten(), #after this we will go for neural network building
    keras.layers.Dense(units=128, activation='relu'), #inputlayers
    keras.layers.Dropout(0.1),
    keras.layers.Dense(units=256, activation='relu'), #Hidden layer
    keras.layers.Dropout(0.25),
    keras.layers.Dense(units=2, activation='softmax') #output layer with 2 neurons
        
])

from tensorflow.keras.optimizers import Adam 
from keras.callbacks import ModelCheckpoint

cnn_model.compile(optimizer=Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model_path='human_horse_predict.h5'

checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

history = cnn_model.fit(train_data1,
                       epochs=10,
                       verbose=1,
                       validation_data=validation_data1,
                       callbacks=callbacks_list)

#Summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Loss')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

model1 = keras.models.load_model(model_path)

##Horse images

h1 = '/content/gdrive/My Drive/asl_alphabet_test/horse-or-human/train/horses/horse01-1.png'
h2 = '/content/gdrive/My Drive/asl_alphabet_test/horse-or-human/train/horses/horse01-2.png'
h3 = '/content/gdrive/My Drive/asl_alphabet_test/horse-or-human/train/horses/horse01-5.png'

#human images 
hu1 = '/content/gdrive/My Drive/asl_alphabet_test/horse-or-human/train/humans/human15-22.png'
hu2 = '/content/gdrive/My Drive/asl_alphabet_test/horse-or-human/train/humans/human14-07.png'
hu3 = '/content/gdrive/My Drive/asl_alphabet_test/horse-or-human/train/humans/human14-06.png'

import numpy as np
from keras.preprocessing import image

def pred_human_horse(model, horse_or_human):
    test_image = image.load_img(horse_or_human, target_size = (150,150,3))
    test_image = image.img_to_array(test_image)/255
    test_image = np.expand_dims(test_image, axis=0)
    
    result = model.predict(test_image).round(3)
    
    pred = np.argmax(result)
    
    if pred==0:
        print("Horse")
    else:
        print("Human")

for horse_or_human in [h1,h2,h3]:
    pred_human_horse(model1, horse_or_human)

for horse_human in [hu1,hu2,hu3]:
    pred_human_horse(model1, horse_human)